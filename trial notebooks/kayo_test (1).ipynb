{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Caricamento test.jsonl e train.jsonl****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T19:33:43.544612Z",
     "iopub.status.busy": "2025-10-30T19:33:43.544257Z",
     "iopub.status.idle": "2025-10-30T19:33:43.551212Z",
     "shell.execute_reply": "2025-10-30T19:33:43.550176Z",
     "shell.execute_reply.started": "2025-10-30T19:33:43.544588Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esquilotorto/.pyenv/versions/3.12.0/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- 1. Import di Scikit-learn ---\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression   \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')  # Suppress all warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T19:33:43.552889Z",
     "iopub.status.busy": "2025-10-30T19:33:43.552561Z",
     "iopub.status.idle": "2025-10-30T19:33:56.613167Z",
     "shell.execute_reply": "2025-10-30T19:33:56.612089Z",
     "shell.execute_reply.started": "2025-10-30T19:33:43.552855Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento riuscito!\n",
      "Riga 4877 rimossa con successo.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_df = pd.read_json('kaggle/input/fds-pokemon-battles-prediction-2025/train.jsonl', lines=True)\n",
    "    test_df = pd.read_json('kaggle/input/fds-pokemon-battles-prediction-2025/test.jsonl', lines=True)\n",
    "    \n",
    "    # Convertiamo subito il target in 1 (Vittoria) e 0 (Sconfitta)\n",
    "    if 'player_won' in train_df.columns:\n",
    "        train_df['player_won'] = train_df['player_won'].astype(int)\n",
    "    print(\"Caricamento riuscito!\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore nel caricamento dati: {e}\")\n",
    "\n",
    "#####\n",
    "riga_da_rimuovere = 4877\n",
    "\n",
    "# Usiamo un controllo per sicurezza, nel caso la riga non esista\n",
    "if riga_da_rimuovere in train_df.index:\n",
    "    train_df = train_df.drop(riga_da_rimuovere)\n",
    "    print(f\"Riga {riga_da_rimuovere} rimossa con successo.\")\n",
    "else:\n",
    "    print(f\"Riga {riga_da_rimuovere} non trovata (forse già rimossa o non presente).\")\n",
    "\n",
    "filtro_livello_100 = train_df['p1_team_details'].apply(\n",
    "    lambda team_list: all(pokemon.get('level') == 100 for pokemon in team_list)\n",
    ")\n",
    "\n",
    "train_df = train_df[filtro_livello_100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T19:33:56.614466Z",
     "iopub.status.busy": "2025-10-30T19:33:56.614170Z",
     "iopub.status.idle": "2025-10-30T19:33:56.627334Z",
     "shell.execute_reply": "2025-10-30T19:33:56.625614Z",
     "shell.execute_reply.started": "2025-10-30T19:33:56.614445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Mappa di efficacia dei tipi per la Generazione 1\n",
    "# Nota: 'Special' in Gen 1 copre sia Atk Sp. che Def Sp.\n",
    "# Non ci sono tipi Dark, Steel, o Fairy.\n",
    "# Source: https://pokemondb.net/type\n",
    "TYPE_CHART_GEN1 = {\n",
    "    'NORMAL': {'ROCK': 0.5, 'GHOST': 0.0},\n",
    "    'FIRE': {'FIRE': 0.5, 'WATER': 0.5, 'GRASS': 2.0, 'ICE': 2.0, 'BUG': 2.0, 'ROCK': 0.5},\n",
    "    'WATER': {'FIRE': 2.0, 'WATER': 0.5, 'GRASS': 0.5, 'GROUND': 2.0, 'ROCK': 2.0, 'DRAGON': 0.5},\n",
    "    'ELECTRIC': {'WATER': 2.0, 'ELECTRIC': 0.5, 'GRASS': 0.5, 'GROUND': 0.0, 'FLYING': 2.0, 'DRAGON': 0.5},\n",
    "    'GRASS': {'FIRE': 0.5, 'WATER': 2.0, 'ELECTRIC': 1.0, 'GRASS': 0.5, 'POISON': 0.5, 'GROUND': 2.0, 'FLYING': 0.5, 'BUG': 0.5, 'ROCK': 2.0, 'DRAGON': 0.5},\n",
    "    'ICE': {'WATER': 0.5, 'GRASS': 2.0, 'ICE': 0.5, 'GROUND': 2.0, 'FLYING': 2.0, 'DRAGON': 2.0},\n",
    "    'FIGHTING': {'NORMAL': 2.0, 'POISON': 0.5, 'FLYING': 0.5, 'PSYCHIC': 0.5, 'BUG': 0.5, 'ROCK': 2.0, 'GHOST': 0.0},\n",
    "    'POISON': {'GRASS': 2.0, 'POISON': 0.5, 'GROUND': 0.5, 'BUG': 2.0, 'ROCK': 0.5, 'GHOST': 0.5},\n",
    "    'GROUND': {'FIRE': 2.0, 'ELECTRIC': 2.0, 'GRASS': 0.5, 'POISON': 2.0, 'FLYING': 0.0, 'BUG': 0.5, 'ROCK': 2.0},\n",
    "    'FLYING': {'ELECTRIC': 0.5, 'GRASS': 2.0, 'FIGHTING': 2.0, 'BUG': 2.0, 'ROCK': 0.5},\n",
    "    'PSYCHIC': {'FIGHTING': 2.0, 'POISON': 2.0, 'PSYCHIC': 0.5, 'GHOST': 1.0}, # In Gen 1, Psychic era immune a Ghost per un bug, ma i dati Showdown potrebbero averlo corretto. Assumiamo 1.0 per sicurezza, o 0.0 se il bug è emulato. Qui usiamo 1.0.\n",
    "    'BUG': {'FIRE': 0.5, 'GRASS': 2.0, 'FIGHTING': 0.5, 'POISON': 2.0, 'FLYING': 0.5, 'PSYCHIC': 2.0},\n",
    "    'ROCK': {'FIRE': 2.0, 'ICE': 2.0, 'FIGHTING': 0.5, 'GROUND': 0.5, 'FLYING': 2.0, 'BUG': 2.0},\n",
    "    'GHOST': {'NORMAL': 0.0, 'PSYCHIC': 0.0, 'GHOST': 2.0}, # Famoso bug: Lick (Ghost) non colpisce Psychic.\n",
    "    'DRAGON': {'DRAGON': 2.0},\n",
    "}\n",
    "\n",
    "# Funzione helper per calcolare l'efficacia\n",
    "def get_type_effectiveness(move_type, target_types):\n",
    "    if move_type not in TYPE_CHART_GEN1:\n",
    "        return 1.0\n",
    "    \n",
    "    multiplier = 1.0\n",
    "    chart_for_move = TYPE_CHART_GEN1[move_type]\n",
    "    \n",
    "    for target_type in target_types:\n",
    "        if target_type in chart_for_move:\n",
    "            multiplier *= chart_for_move[target_type]\n",
    "            \n",
    "    return multiplier\n",
    "\n",
    "# Pokémon dominanti nel metagame Gen 1 OU (S-Tier e A-Tier)\n",
    "# La loro presenza è un segnale fortissimo.\n",
    "META_THREATS_GEN1 = {\n",
    "    'Snorlax', 'Tauros', 'Chansey', 'Alakazam', 'Starmie', 'Exeggutor', \n",
    "    'Zapdos', 'Jolteon', 'Rhydon', 'Golem', 'Lapras'\n",
    "}\n",
    "\n",
    "# Mosse di setup o status chiave\n",
    "STATUS_MOVES = {'Thunder Wave', 'Sleep Powder', 'Sing', 'Toxic', 'Lovely Kiss', 'Spore', 'Stun Spore', 'Glare'}\n",
    "SETUP_MOVES = {'Amnesia', 'Swords Dance', 'Agility', 'Growth'}\n",
    "\n",
    "def get_best_stab_advantage(attacker_types, defender_types):\n",
    "    \"\"\"\n",
    "    Calculates the best possible STAB multiplier an attacker has against a defender.\n",
    "    \"\"\"\n",
    "    # Clean 'notype' from lists\n",
    "    attacker_types = [t for t in attacker_types if t.upper() != 'NOTYPE']\n",
    "    defender_types = [t for t in defender_types if t.upper() != 'NOTYPE']\n",
    "\n",
    "    if not attacker_types:\n",
    "        return 1.0 # No types, no STAB advantage\n",
    "\n",
    "    best_multiplier = 0.0\n",
    "    \n",
    "    for move_type in attacker_types:\n",
    "        # Get the multiplier for this STAB type against the defender's types\n",
    "        multiplier = get_type_effectiveness(move_type.upper(), [t.upper() for t in defender_types])\n",
    "        \n",
    "        # We're looking for the *best* STAB move\n",
    "        if multiplier > best_multiplier:\n",
    "            best_multiplier = multiplier\n",
    "            \n",
    "    # If no STAB move is effective (e.g., Normal vs. Ghost), multiplier is 0.\n",
    "    # Otherwise, it's the best one we found.\n",
    "    # If best_multiplier is 0, we should return 0, not 1.\n",
    "    if best_multiplier == 0.0:\n",
    "        # Check if any type was effective at all, even if not > 0\n",
    "        # This handles neutral hits (1.0)\n",
    "        is_neutral = any(get_type_effectiveness(t.upper(), [d.upper() for d in defender_types]) >= 1.0 for t in attacker_types)\n",
    "        if is_neutral:\n",
    "             return 1.0\n",
    "        \n",
    "    return best_multiplier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking of most important stats in a pokemon battle.\n",
    "- Pokemon type\n",
    "- Speed stat\n",
    "- Moveset\n",
    "    - STAB attack\n",
    "    - Coverage\n",
    "    - Utility/Status\n",
    "- HP, Attack, Defense, Special Attack, and Special Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_features(df):\n",
    "    processed_data = []\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Creazione features\"):\n",
    "        p1_team = row['p1_team_details']\n",
    "        p2_lead = row['p2_lead_details']\n",
    "        timeline = row['battle_timeline']\n",
    "        p1_lead = p1_team[0]\n",
    "        \n",
    "        # --- Static Features ---\n",
    "        feat_lead_speed_diff = p1_lead['base_spe'] - p2_lead['base_spe']\n",
    "        feat_lead_hp_diff = p1_lead['base_hp'] - p2_lead['base_hp']\n",
    "        feat_lead_atk_diff = p1_lead['base_atk'] - p2_lead['base_atk']\n",
    "        feat_lead_def_diff = p1_lead['base_def'] - p2_lead['base_def']\n",
    "        feat_lead_spa_diff = p1_lead['base_spa'] - p2_lead['base_spa']\n",
    "        feat_lead_spd_diff = p1_lead['base_spd'] - p2_lead['base_spd']\n",
    "        \n",
    "        # --- Lead Type Advantage ---\n",
    "        p1_lead_types = [t for t in p1_lead['types'] if t != 'notype']\n",
    "        p2_lead_types = [t for t in p2_lead['types'] if t != 'notype']\n",
    "        \n",
    "        p1_best_adv = get_best_stab_advantage(p1_lead_types, p2_lead_types)\n",
    "        p2_best_adv = get_best_stab_advantage(p2_lead_types, p1_lead_types)\n",
    "        \n",
    "        # A positive number means P1's STABs are more effective\n",
    "        feat_lead_type_adv_diff = p1_best_adv - p2_best_adv\n",
    "\n",
    "        # Statistiche aggregate P1\n",
    "        feat_p1_team_avg_atk = np.mean([p['base_atk'] for p in p1_team])\n",
    "        feat_p1_team_avg_spe = np.mean([p['base_spe'] for p in p1_team])\n",
    "        feat_p1_team_max_hp = np.max([p['base_hp'] for p in p1_team])\n",
    "        \n",
    "        # Using 'base_spa' as it's identical to 'base_spd' in Gen 1 data\n",
    "        feat_p1_team_avg_special = np.mean([p['base_spa'] for p in p1_team])\n",
    "        \n",
    "        # Meta threats\n",
    "        feat_p1_team_meta_count = sum(1 for p in p1_team if p['name'].title() in META_THREATS_GEN1)\n",
    "        feat_p2_lead_is_meta = 1 if p2_lead['name'].title() in META_THREATS_GEN1 else 0\n",
    "        \n",
    "        p2_lead_speed = p2_lead['base_spe']\n",
    "        feat_team_speed_adv_vs_lead = sum(1 for p in p1_team if p['base_spe'] > p2_lead_speed)\n",
    "\n",
    "        # --- Dynamic Features (Timeline) ---\n",
    "        p1_seen_status = {p['name']: {'hp_pct': 100, 'status': None} for p in p1_team}\n",
    "        p2_seen_status = {p2_lead['name']: {'hp_pct': 100, 'status': None}}\n",
    "        \n",
    "        feat_end_boost_diff = 0\n",
    "        p1_status_moves = 0\n",
    "        p1_setup_moves = 0\n",
    "        p2_status_moves = 0\n",
    "        p2_setup_moves = 0\n",
    "        \n",
    "        p1_total_bp = 0\n",
    "        p2_total_bp = 0\n",
    "        p1_confused_turns = 0\n",
    "        p2_confused_turns = 0\n",
    "        p1_active_hp_end = 100 \n",
    "        p2_active_hp_end = 100 \n",
    "        \n",
    "        last_turn_num = 0 \n",
    "\n",
    "        if timeline:\n",
    "            last_turn_num = timeline[-1].get('turn', 0)\n",
    "            for turn in timeline:\n",
    "                p1_state = turn.get('p1_pokemon_state')\n",
    "                if p1_state and p1_state.get('name'):\n",
    "                    p1_name = p1_state['name']\n",
    "                    p1_seen_status.setdefault(p1_name, {'hp_pct': 100, 'status': None})\n",
    "                    p1_seen_status[p1_name]['hp_pct'] = p1_state.get('hp_pct', p1_seen_status[p1_name]['hp_pct'])\n",
    "                    p1_seen_status[p1_name]['status'] = p1_state.get('status', p1_seen_status[p1_name]['status'])\n",
    "                    \n",
    "                    if 'confusion' in p1_state.get('volatile_effects', []):\n",
    "                        p1_confused_turns += 1\n",
    "                    \n",
    "                p2_state = turn.get('p2_pokemon_state')\n",
    "                if p2_state and p2_state.get('name'):\n",
    "                    p2_name = p2_state['name']\n",
    "                    p2_seen_status.setdefault(p2_name, {'hp_pct': 100, 'status': None})\n",
    "                    p2_seen_status[p2_name]['hp_pct'] = p2_state.get('hp_pct', p2_seen_status[p2_name]['hp_pct'])\n",
    "                    p2_seen_status[p2_name]['status'] = p2_state.get('status', p2_seen_status[p2_name]['status'])\n",
    "                    \n",
    "                    if 'confusion' in p2_state.get('volatile_effects', []):\n",
    "                        p2_confused_turns += 1\n",
    "\n",
    "                p1_move = turn.get('p1_move_details')\n",
    "                if p1_move:\n",
    "                    move_name_p1 = p1_move.get('name', '').title()\n",
    "                    if move_name_p1 in STATUS_MOVES: p1_status_moves += 1\n",
    "                    if move_name_p1 in SETUP_MOVES: p1_setup_moves += 1\n",
    "                    if p1_move.get('base_power'):\n",
    "                        p1_total_bp += p1_move['base_power']\n",
    "                    \n",
    "                p2_move = turn.get('p2_move_details')\n",
    "                if p2_move:\n",
    "                    move_name_p2 = p2_move.get('name', '').title()\n",
    "                    if move_name_p2 in STATUS_MOVES: p2_status_moves += 1\n",
    "                    if move_name_p2 in SETUP_MOVES: p2_setup_moves += 1\n",
    "                    if p2_move.get('base_power'):\n",
    "                        p2_total_bp += p2_move['base_power']\n",
    "\n",
    "                if turn.get('turn') == last_turn_num:\n",
    "                    p1_boosts = sum(p1_state.get('boosts', {}).values()) if p1_state else 0\n",
    "                    p2_boosts = sum(p2_state.get('boosts', {}).values()) if p2_state else 0\n",
    "                    feat_end_boost_diff = p1_boosts - p2_boosts\n",
    "                    \n",
    "                    p1_active_hp_end = p1_state.get('hp_pct', 0) if p1_state else 0\n",
    "                    p2_active_hp_end = p2_state.get('hp_pct', 0) if p2_state else 0\n",
    "\n",
    "        # Calcoli finali\n",
    "        p1_total_hp_seen = sum(p['hp_pct'] for p in p1_seen_status.values())\n",
    "        p2_total_hp_seen = sum(p['hp_pct'] for p in p2_seen_status.values())\n",
    "        feat_hp_advantage_seen = p1_total_hp_seen - p2_total_hp_seen\n",
    "        \n",
    "        feat_mons_revealed_diff = len(p2_seen_status) - len(p1_seen_status)\n",
    "        \n",
    "        p1_team_status_count = sum(1 for p in p1_seen_status.values() if p['status'] is not None)\n",
    "        p2_team_status_count = sum(1 for p in p2_seen_status.values() if p['status'] is not None)\n",
    "        feat_team_status_diff = p1_team_status_count - p2_team_status_count\n",
    "\n",
    "        feat_status_move_diff = p1_status_moves - p2_status_moves\n",
    "        feat_setup_move_diff = p1_setup_moves - p2_setup_moves\n",
    "        \n",
    "        p1_fainted_count = sum(1 for p in p1_seen_status.values() if p['hp_pct'] == 0)\n",
    "        p2_fainted_count = sum(1 for p in p2_seen_status.values() if p['hp_pct'] == 0)\n",
    "        feat_fainted_mons_diff = p2_fainted_count - p1_fainted_count \n",
    "\n",
    "        feat_hp_advantage_active = p1_active_hp_end - p2_active_hp_end\n",
    "        \n",
    "        feat_total_base_power_diff = p1_total_bp - p2_total_bp\n",
    "        feat_volatile_status_diff = p2_confused_turns - p1_confused_turns \n",
    "\n",
    "        processed_data.append({\n",
    "            'battle_id': row['battle_id'],\n",
    "            # Categoriche\n",
    "            'p1_lead_name': p1_lead['name'], \n",
    "            'p2_lead_name': p2_lead['name'],\n",
    "            # Numeriche (Core)\n",
    "            'lead_speed_diff': feat_lead_speed_diff,\n",
    "            'hp_advantage_seen': feat_hp_advantage_seen,\n",
    "            'mons_revealed_diff': feat_mons_revealed_diff,\n",
    "            'team_status_diff': feat_team_status_diff,\n",
    "            'end_boost_diff': feat_end_boost_diff,\n",
    "            # Numeriche (Aggregati Team e Meta)\n",
    "            'p1_team_avg_atk': feat_p1_team_avg_atk,\n",
    "            'p1_team_avg_spe': feat_p1_team_avg_spe,\n",
    "            'p1_team_max_hp': feat_p1_team_max_hp,\n",
    "            'p1_team_meta_count': feat_p1_team_meta_count,\n",
    "            'p2_lead_is_meta': feat_p2_lead_is_meta,\n",
    "            # Numeriche (Aggregati Mosse)\n",
    "            'status_move_diff': feat_status_move_diff,\n",
    "            'setup_move_diff': feat_setup_move_diff,\n",
    "            'total_base_power_diff': feat_total_base_power_diff,\n",
    "            'volatile_status_diff': feat_volatile_status_diff,\n",
    "            # Numeriche (Lead Diffs)\n",
    "            'lead_hp_diff': feat_lead_hp_diff,\n",
    "            'lead_atk_diff': feat_lead_atk_diff,\n",
    "            'lead_def_diff': feat_lead_def_diff,\n",
    "            'lead_spa_diff': feat_lead_spa_diff,\n",
    "            'lead_spd_diff': feat_lead_spd_diff,\n",
    "            # Numeriche (Momentum)\n",
    "            'team_speed_adv_vs_lead': feat_team_speed_adv_vs_lead,\n",
    "            'fainted_mons_diff': feat_fainted_mons_diff,\n",
    "            'hp_advantage_active': feat_hp_advantage_active,\n",
    "            \n",
    "            # --- ADD NEW FEATURES HERE ---\n",
    "            'lead_type_adv_diff': feat_lead_type_adv_diff,\n",
    "            'p1_team_avg_special': feat_p1_team_avg_special\n",
    "            \n",
    "        })\n",
    "    return pd.DataFrame(processed_data).set_index('battle_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T19:33:56.656311Z",
     "iopub.status.busy": "2025-10-30T19:33:56.655985Z",
     "iopub.status.idle": "2025-10-30T19:33:58.899040Z",
     "shell.execute_reply": "2025-10-30T19:33:58.897844Z",
     "shell.execute_reply.started": "2025-10-30T19:33:56.656287Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio feature engineering avanzata sul set di training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creazione features:   0%|          | 0/9996 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creazione features: 100%|██████████| 9996/9996 [00:02<00:00, 4605.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inizio feature engineering avanzata sul set di test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creazione features: 100%|██████████| 5000/5000 [00:01<00:00, 4545.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature engineering completato. Esempio di dati trasformati:\n",
      "          p1_lead_name p2_lead_name  ...  lead_type_adv_diff  p1_team_avg_special\n",
      "battle_id                            ...                                         \n",
      "0              starmie      starmie  ...                 0.0           100.000000\n",
      "1                 jynx     alakazam  ...                 0.5            90.000000\n",
      "2            exeggutor      chansey  ...                 0.0            90.000000\n",
      "3               gengar       tauros  ...                 1.0           103.333333\n",
      "4             alakazam      starmie  ...                -0.5            97.500000\n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Inizio feature engineering avanzata sul set di training...\")\n",
    "X_train_features = create_advanced_features(train_df)\n",
    "\n",
    "print(\"\\nInizio feature engineering avanzata sul set di test...\")\n",
    "X_test_features = create_advanced_features(test_df)\n",
    "\n",
    "# Definiamo la nostra variabile target 'y'\n",
    "y_train = train_df.set_index('battle_id')['player_won']\n",
    "\n",
    "# Allineiamo X e y\n",
    "y_train = y_train.loc[X_train_features.index]\n",
    "\n",
    "print(\"\\nFeature engineering completato. Esempio di dati trasformati:\")\n",
    "print(X_train_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T19:33:58.900385Z",
     "iopub.status.busy": "2025-10-30T19:33:58.900038Z",
     "iopub.status.idle": "2025-10-30T19:33:58.907357Z",
     "shell.execute_reply": "2025-10-30T19:33:58.906149Z",
     "shell.execute_reply.started": "2025-10-30T19:33:58.900353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 1. Definizione delle Feature ---\n",
    "\n",
    "numeric_features = [\n",
    "    'lead_speed_diff',\n",
    "    'hp_advantage_seen',\n",
    "    'mons_revealed_diff',\n",
    "    'team_status_diff',\n",
    "    'end_boost_diff',\n",
    "    \n",
    "    'p1_team_avg_atk',\n",
    "    'p1_team_avg_spe',\n",
    "    'p1_team_max_hp',\n",
    "    'p1_team_meta_count',\n",
    "    'p2_lead_is_meta',\n",
    "    \n",
    "    'lead_type_adv_diff',\n",
    "    'p1_team_avg_special',\n",
    "    \n",
    "    'status_move_diff',\n",
    "    'setup_move_diff',\n",
    "    'total_base_power_diff',\n",
    "    'volatile_status_diff',\n",
    "\n",
    "    'lead_hp_diff',\n",
    "    'lead_atk_diff',\n",
    "    'lead_def_diff',\n",
    "    'lead_spa_diff',\n",
    "    'lead_spd_diff',\n",
    "\n",
    "    'team_speed_adv_vs_lead',\n",
    "    'fainted_mons_diff',\n",
    "    'hp_advantage_active'\n",
    "]\n",
    "\n",
    "categorical_features = ['p1_lead_name', 'p2_lead_name']\n",
    "\n",
    "\n",
    "# --- 2. Creazione del Preprocessor ---\n",
    "\n",
    "# Creiamo i trasformatori (StandardScaler e OneHotEncoder)\n",
    "numeric_transformer = Pipeline(steps=[('scaler', RobustScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T19:33:58.908531Z",
     "iopub.status.busy": "2025-10-30T19:33:58.908221Z",
     "iopub.status.idle": "2025-10-30T19:33:59.032664Z",
     "shell.execute_reply": "2025-10-30T19:33:59.031317Z",
     "shell.execute_reply.started": "2025-10-30T19:33:58.908506Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensione Training Split: (7996, 26)\n",
      "Dimensione Validation Split: (2000, 26)\n",
      "\n",
      "Allenamento del modello baseline...\n",
      "\n",
      "--- Risultati Modello Baseline ---\n",
      "Accuracy sul Validation Set: 0.8050\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dividiamo i dati di training per una validazione locale\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_features, \n",
    "    y_train, \n",
    "    test_size=0.2, # 20% per la validazione\n",
    "    random_state=42,\n",
    "    stratify=y_train # Mantiene l'equilibrio delle classi\n",
    ")\n",
    "\n",
    "print(f\"Dimensione Training Split: {X_train_split.shape}\")\n",
    "print(f\"Dimensione Validation Split: {X_val_split.shape}\")\n",
    "\n",
    "# 1. Creiamo la pipeline con un modello \"di default\"\n",
    "# Usiamo C=1.0 come valore predefinito\n",
    "baseline_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000, solver='liblinear', C=1.0))\n",
    "])\n",
    "\n",
    "# 2. Alleniamo il modello base SUL SOLO SET DI TRAINING SPLIT\n",
    "print(\"\\nAllenamento del modello baseline...\")\n",
    "baseline_pipeline.fit(X_train_split, y_train_split)\n",
    "\n",
    "# 3. Valutiamo il modello base SUL SET DI VALIDAZIONE\n",
    "y_val_pred = baseline_pipeline.predict(X_val_split)\n",
    "val_accuracy = accuracy_score(y_val_split, y_val_pred)\n",
    "\n",
    "print(f\"\\n--- Risultati Modello Baseline ---\")\n",
    "print(f\"Accuracy sul Validation Set: {val_accuracy:.4f}\")\n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T19:33:59.034317Z",
     "iopub.status.busy": "2025-10-30T19:33:59.033990Z",
     "iopub.status.idle": "2025-10-30T19:36:00.810625Z",
     "shell.execute_reply": "2025-10-30T19:36:00.809433Z",
     "shell.execute_reply.started": "2025-10-30T19:33:59.034293Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L'ottimizzazione degli iperparametri...\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "\n",
      "--- Risultati GridSearchCV ---\n",
      "Migliori parametri trovati: {'classifier__C': 500, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear', 'selectkbest__k': 50}\n",
      "Migliore Accuracy (media CV): 0.8337\n",
      "------------------------------\n",
      "Accuracy media: 83.37%\n",
      "Deviazione Standard (Stabilità) del modello: 1.34%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "print(\"\\nL'ottimizzazione degli iperparametri...\")\n",
    "# 1. Creiamo la pipeline (la stessa di prima, ma senza 'C' definito)\n",
    "# La pipeline che verrà testata da GridSearchCV\n",
    "tuning_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('selectkbest', SelectKBest(score_func=f_classif)),  # <-- NUOVA FASE\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000, solver='liblinear'))\n",
    "])\n",
    "\n",
    "# 2. Definiamo la griglia dei parametri\n",
    "# Vogliamo testare diversi valori per 'classifier__C'\n",
    "param_grid = {\n",
    "    'selectkbest__k': [30, 40, 50], # Quanti features tenere\n",
    "    'classifier__penalty': ['l1'],\n",
    "    'classifier__C': [100, 200, 500],       # La nuova grid per C\n",
    "    'classifier__solver': ['liblinear'] \n",
    "}\n",
    "\n",
    "# 3. Impostiamo GridSearchCV\n",
    "# cv=5 significa 5-fold cross-validation\n",
    "# scoring='accuracy' è la nostra metrica\n",
    "# n_jobs=-1 usa tutti i processori\n",
    "grid_search = GridSearchCV(\n",
    "    tuning_pipeline, \n",
    "    param_grid, \n",
    "    cv=10, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    verbose=1 # Mostra i log\n",
    ")\n",
    "\n",
    "# 4. Avviamo la ricerca sull'INTERO set di training\n",
    "# (GridSearchCV gestirà internamente le divisioni di cross-validation)\n",
    "grid_search.fit(X_train_features, y_train)\n",
    "\n",
    "# 5. Analizziamo i risultati\n",
    "print(\"\\n--- Risultati GridSearchCV ---\")\n",
    "print(f\"Migliori parametri trovati: {grid_search.best_params_}\")\n",
    "print(f\"Migliore Accuracy (media CV): {grid_search.best_score_:.4f}\")\n",
    "print(\"------------------------------\")\n",
    "\n",
    "best_index = grid_search.best_index_\n",
    "# (std_test_score è la colonna che la contiene)\n",
    "std_dev_del_modello = grid_search.cv_results_['std_test_score'][best_index]\n",
    "\n",
    "print(f\"Accuracy media: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"Deviazione Standard (Stabilità) del modello: {std_dev_del_modello * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T19:36:00.812829Z",
     "iopub.status.busy": "2025-10-30T19:36:00.811920Z",
     "iopub.status.idle": "2025-10-30T19:38:00.515790Z",
     "shell.execute_reply": "2025-10-30T19:38:00.513840Z",
     "shell.execute_reply.started": "2025-10-30T19:36:00.812800Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generazione delle predizioni sul set di test...\n",
      "--- Accuracy di Validazione (stima): 80.50% ---\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "\n",
      "--- Risultati GridSearchCV ---\n",
      "Migliori parametri trovati: {'classifier__C': 500, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear', 'selectkbest__k': 50}\n",
      "Migliore Accuracy (media CV): 0.8337\n",
      "Accuracy del 'final_model' sul set di validazione: 83.25%\n",
      "Accuracy (media da Cross-Validation): 83.37%\n"
     ]
    }
   ],
   "source": [
    "# 1. Il nostro modello finale è il 'best_estimator_' trovato da GridSearch\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nGenerazione delle predizioni sul set di test...\")\n",
    "# 2. Usiamo il modello finale per predire sul set di test (X_test_features)\n",
    "test_predictions = final_model.predict(X_test_features)\n",
    "\n",
    "# Ignoriamo i warning per pulizia\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# --- FASE 1: VALIDAZIONE ---\n",
    "\n",
    "# Dividi i dati di training per la validazione\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_features, y_train, test_size=0.20, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# Allena un modello base (es. 'baseline_pipeline') sulla parte splittata\n",
    "baseline_pipeline.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Calcola l'accuracy sul set di validazione\n",
    "y_val_pred = baseline_pipeline.predict(X_val_split)\n",
    "val_accuracy = accuracy_score(y_val_split, y_val_pred)\n",
    "\n",
    "print(f\"--- Accuracy di Validazione (stima): {val_accuracy * 100:.2f}% ---\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# --- FASE 2: ALLENAMENTO DEL MODELLO OTTIMIZZATO ---\n",
    "\n",
    "# Allena il GridSearchCV su TUTTI i dati di training\n",
    "# (Questo è il 'grid_search' definito nel Passaggio 6 della risposta precedente)\n",
    "grid_search.fit(X_train_features, y_train)\n",
    "\n",
    "print(f\"\\n--- Risultati GridSearchCV ---\")\n",
    "print(f\"Migliori parametri trovati: {grid_search.best_params_}\")\n",
    "print(f\"Migliore Accuracy (media CV): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 1. Il tuo modello finale e ottimizzato è pronto\n",
    "final_model = grid_search.best_estimator_\n",
    "cv_accuracy = grid_search.best_score_\n",
    "\n",
    "# 2. Usa il tuo modello finale (ottimizzato) per fare previsioni\n",
    "#    sul set di validazione (X_val_split)\n",
    "y_val_pred = final_model.predict(X_val_split)\n",
    "\n",
    "# 3. Calcola l'accuracy confrontando le previsioni (y_val_pred)\n",
    "#    con le risposte vere (y_val_split)\n",
    "final_model_accuracy = accuracy_score(y_val_split, y_val_pred)\n",
    "\n",
    "print(f\"Accuracy del 'final_model' sul set di validazione: {final_model_accuracy * 100:.2f}%\")\n",
    "\n",
    "print(f\"Accuracy (media da Cross-Validation): {cv_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T19:38:00.519433Z",
     "iopub.status.busy": "2025-10-30T19:38:00.519081Z",
     "iopub.status.idle": "2025-10-30T19:38:00.533004Z",
     "shell.execute_reply": "2025-10-30T19:38:00.531851Z",
     "shell.execute_reply.started": "2025-10-30T19:38:00.519411Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Importanza delle Feature (Coefficienti del Modello) ---\n",
      "                        Feature  Coefficient      Impact\n",
      "3         num__team_status_diff   206.208007  206.208007\n",
      "1        num__hp_advantage_seen   105.771754  105.771754\n",
      "2       num__mons_revealed_diff   105.030090  105.030090\n",
      "38    cat__p2_lead_name_chansey    -9.428868    9.428868\n",
      "22    cat__p1_lead_name_chansey     9.233678    9.233678\n",
      "23   cat__p1_lead_name_cloyster    -7.605669    7.605669\n",
      "39   cat__p2_lead_name_cloyster     6.898832    6.898832\n",
      "32    cat__p1_lead_name_snorlax     4.068268    4.068268\n",
      "47    cat__p2_lead_name_snorlax    -4.000245    4.000245\n",
      "42      cat__p2_lead_name_golem     3.522784    3.522784\n",
      "21   cat__p1_lead_name_articuno    -3.206037    3.206037\n",
      "14           num__lead_def_diff     2.627333    2.627333\n",
      "44     cat__p2_lead_name_lapras    -2.486974    2.486974\n",
      "26      cat__p1_lead_name_golem    -1.963348    1.963348\n",
      "29     cat__p1_lead_name_lapras     1.877254    1.877254\n",
      "33    cat__p1_lead_name_starmie    -1.740681    1.740681\n",
      "43       cat__p2_lead_name_jynx    -1.632259    1.632259\n",
      "34     cat__p1_lead_name_tauros    -1.570596    1.570596\n",
      "27    cat__p1_lead_name_jolteon    -1.182250    1.182250\n",
      "49     cat__p2_lead_name_tauros     1.155654    1.155654\n",
      "37   cat__p2_lead_name_articuno     1.101187    1.101187\n",
      "28       cat__p1_lead_name_jynx     1.060503    1.060503\n",
      "48    cat__p2_lead_name_starmie     0.984645    0.984645\n",
      "25     cat__p1_lead_name_gengar    -0.789466    0.789466\n",
      "45    cat__p2_lead_name_persian     0.768898    0.768898\n",
      "35     cat__p1_lead_name_zapdos    -0.713196    0.713196\n",
      "20   cat__p1_lead_name_alakazam    -0.539131    0.539131\n",
      "30     cat__p1_lead_name_rhydon    -0.498095    0.498095\n",
      "0          num__lead_speed_diff     0.438789    0.438789\n",
      "36   cat__p2_lead_name_alakazam    -0.380962    0.380962\n",
      "12            num__lead_hp_diff    -0.377593    0.377593\n",
      "31    cat__p1_lead_name_slowbro    -0.373577    0.373577\n",
      "17  num__team_speed_adv_vs_lead    -0.336834    0.336834\n",
      "18       num__fainted_mons_diff     0.290254    0.290254\n",
      "40  cat__p2_lead_name_exeggutor    -0.260687    0.260687\n",
      "15           num__lead_spa_diff     0.226974    0.226974\n",
      "19     num__hp_advantage_active     0.195090    0.195090\n",
      "41     cat__p2_lead_name_gengar     0.181672    0.181672\n",
      "13           num__lead_atk_diff    -0.180870    0.180870\n",
      "16           num__lead_spd_diff     0.147499    0.147499\n",
      "5          num__p1_team_avg_atk    -0.129081    0.129081\n",
      "7       num__lead_type_adv_diff     0.123666    0.123666\n",
      "10         num__setup_move_diff    -0.103819    0.103819\n",
      "24  cat__p1_lead_name_exeggutor     0.099763    0.099763\n",
      "4           num__end_boost_diff     0.090292    0.090292\n",
      "46     cat__p2_lead_name_rhydon     0.085437    0.085437\n",
      "8      num__p1_team_avg_special     0.081124    0.081124\n",
      "11   num__total_base_power_diff    -0.064802    0.064802\n",
      "9         num__status_move_diff     0.029576    0.029576\n",
      "6           num__p1_team_max_hp    -0.003374    0.003374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Estrai il modello migliore (la pipeline completa) da GridSearchCV\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "# 2. Estrai i passaggi della pipeline\n",
    "preprocessor = final_model.named_steps['preprocessor']\n",
    "selector = final_model.named_steps['selectkbest']\n",
    "classifier = final_model.named_steps['classifier']\n",
    "\n",
    "# 3. Estrai i coefficienti (l'importanza) - questo è corretto (avrà lunghezza 40)\n",
    "coefficients = classifier.coef_[0]\n",
    "\n",
    "# 4.\n",
    "# Dobbiamo ottenere i nomi di TUTTE le feature DAL PREPROCESSOR\n",
    "# e poi filtrarli in base a QUALI feature sono state scelte da SelectKBest.\n",
    "\n",
    "try:\n",
    "    # A. Ottieni tutti i 62 nomi delle feature dal preprocessor\n",
    "    all_feature_names = preprocessor.get_feature_names_out()\n",
    "    \n",
    "    # B. Ottieni la \"maschera\" booleana da SelectKBest (un array di True/False lungo 62)\n",
    "    mask = selector.get_support()\n",
    "    \n",
    "    # C. Applica la maschera ai nomi per ottenere solo i 40 nomi selezionati\n",
    "    # Converti i nomi in un array numpy per un facile filtraggio\n",
    "    selected_feature_names = np.array(all_feature_names)[mask]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Errore con get_feature_names_out o get_support: {e}\")\n",
    "    # Il tuo fallback originale (potrebbe non funzionare con SelectKBest)\n",
    "    try:\n",
    "        categorical_names = preprocessor.named_transformers_['cat'] \\\n",
    "                                         .named_steps['onehot'] \\\n",
    "                                         .get_feature_names_out(categorical_features)\n",
    "    except AttributeError:\n",
    "        categorical_names = preprocessor.named_transformers_['cat'] \\\n",
    "                                         .named_steps['onehot'] \\\n",
    "                                         .get_feature_names_out()\n",
    "    all_feature_names = numeric_features + list(categorical_names)\n",
    "    mask = selector.get_support()\n",
    "    selected_feature_names = np.array(all_feature_names)[mask]\n",
    "\n",
    "\n",
    "# 5. Controlla le lunghezze (ora 40 == 40)\n",
    "if len(selected_feature_names) != len(coefficients):\n",
    "    print(f\"ERRORE: La lunghezza dei nomi ({len(selected_feature_names)}) non corrisponde a quella dei coefficienti ({len(coefficients)})\")\n",
    "    print(\"C'è ancora un problema logico nel recuperare i nomi o la maschera.\")\n",
    "else:\n",
    "    # 6. Crea un DataFrame per visualizzarli in modo chiaro\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': selected_feature_names, # Usa i nomi filtrati\n",
    "        'Coefficient': coefficients\n",
    "    })\n",
    "\n",
    "    # 7. Aggiungi il 'Coefficiente Assoluto' per ordinare per impatto (sia positivo che negativo)\n",
    "    importance_df['Impact'] = importance_df['Coefficient'].abs()\n",
    "    importance_df = importance_df.sort_values(by='Impact', ascending=False)\n",
    "\n",
    "    # 8. Stampa i risultati\n",
    "    print(\"--- Importanza delle Feature (Coefficienti del Modello) ---\")\n",
    "    print(importance_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T19:38:00.534370Z",
     "iopub.status.busy": "2025-10-30T19:38:00.533989Z",
     "iopub.status.idle": "2025-10-30T19:38:00.588563Z",
     "shell.execute_reply": "2025-10-30T19:38:00.587580Z",
     "shell.execute_reply.started": "2025-10-30T19:38:00.534344Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------\n",
      "File 'submission_predictions.csv' creato con successo!\n",
      "Ora conterrà 1 e 0, e colonne separate.\n",
      "-------------------------------------------------\n",
      "   battle_id  player_won\n",
      "0          0           0\n",
      "1          1           1\n",
      "2          2           1\n",
      "3          3           1\n",
      "4          4           1\n"
     ]
    }
   ],
   "source": [
    "# 1. Estrai il modello finale\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "# 2. Genera le predizioni (saranno True/False)\n",
    "test_predictions_bool = final_model.predict(X_test_features)\n",
    "\n",
    "# 3. Converti True/False in 1/0 ---\n",
    "# .astype(int) converte True -> 1 e False -> 0\n",
    "test_predictions_int = test_predictions_bool.astype(int)\n",
    "\n",
    "# 4. Prendi i battle_id dall'indice\n",
    "test_battle_ids = X_test_features.index\n",
    "\n",
    "# 5. Crea il DataFrame con le due colonne CORRETTE\n",
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': test_battle_ids,\n",
    "    'player_won': test_predictions_int  # Usa la versione 1/0\n",
    "})\n",
    "\n",
    "# 6. Salva SENZA l'indice di pandas ---\n",
    "# Aggiungendo 'index=False' si risolve il problema della \"stessa colonna\".\n",
    "submission_df.to_csv('submission_predictions.csv', index=False)\n",
    "\n",
    "print(\"\\n-------------------------------------------------\")\n",
    "print(\"File 'submission_predictions.csv' creato con successo!\")\n",
    "print(\"Ora conterrà 1 e 0, e colonne separate.\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "# Stampa un'anteprima\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13033998,
     "sourceId": 107555,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "3.12.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
